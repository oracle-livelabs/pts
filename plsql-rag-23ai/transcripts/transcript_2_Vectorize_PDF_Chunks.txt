In this video, we're using the PL/SQL package DBMS_VECTOR_CHAIN to process a complex PDF file, converting it to plain text, segmenting it into chunks, and then vectorizing those chunks. This allows us to perform similarity searches, retrieval, or text generation based on the contents of the PDF document.

The PDF document in question is substantial, spanning 158 pages with numerous tables and columns. Its complexity is intentional to demonstrate the capabilities of the process. Let's delve into it.

Firstly, we start by using 'sys' for the pluggable database. We perform some necessary grants, logging in as 'sys' and granting the 'create mining' privilege to our vector schema user while creating directory objects for easy file loading. Additionally, we grant read permissions on those objects. This administrative setup is essential before proceeding.

Now, we log in as our schema user. Since we'll be creating vectors, we'll utilize an ONNX model. We drop any existing models and proceed to load the ONNX model.

We won't create a table to load files into the database. Instead, we'll use an existing table with a BLOB column to store binary PDF files. We insert the PDF file into this table. Considering it's 158 pages long, the insertion is swift.

A quick SELECT confirms the successful insertion. With the setup complete, we proceed to execute SQL statements. Before that, we set up some parameters in JSON format. These parameters define chunking behavior and model selection for vector creation.

Now, let's perform the actual processing. We'll convert the PDF file, stored as a BLOB in the database, into plain text using a package procedure. The output will then be segmented into chunks, and corresponding vectors will be created.

Executing the SQL statement, we observe the transformation. The 158-page PDF is segmented into 2085 rows of chunks in the table. However, the output isn't easy to interpret. Instead of displaying it on the screen, we opt to store it in a table called 'dagor_sung'.

Creating this table, we format the output as relational columns rather than JSON. This allows for easier data extraction and analysis. Upon examining the table, we find it more useful, with columns for chunk IDs, chunks, and vectors.

The text from the PDF is successfully converted to plain text, segmented into chunks, and vectorized. To streamline the process for multiple documents, we insert the results into a single table rather than creating a table for each document.

With a single SQL statement, we've achieved significant functionality, handling PDF conversion, chunking, and vectorization. In the next videos, we'll explore further functionalities of the DBMS_VECTOR_CHAIN PL/SQL package."