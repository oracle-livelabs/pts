# Deploy file processing components

## Introduction

Oracle cloud resources like object storage, compute nodes and database instances can be used to build complex workflows. With minimal knowledge and out-of-the-box tools, you can combine them into complex configurations. Everything can be automated using custom code in scripts, stored procedures and data structures.

This lab explains how to connect cloud resources to build a simple solution for your problem.

Estimated Time: 40 minutes

### Objectives

In this lab you will:
* Create credentials and access object storage assets
* Create tables and views to track file processing
* Create procedures for data processing inside Oracle database
* Write Bash (Bourne Again Shell) scripts for file type conversions
* Create external tables based on flat files

### Prerequisites

This lab assumes you have:
* Provisioned Oracle Cloud Resources completing the first lab
* Basic knowledge of Linux Bash programming
* Intermediate Oracle SQL and PL/SQL experience

## Task 1: Create OCI credentials to access files in bucket

1. On the previous tab where ADMIN user is connected to Database Actions, click main menu â‰¡ or Database Actions in the lower-left corner, and **SQL**.

    ![Database Actions SQL](./images/db-actions-sql.png "")

2. Grant privileges on `DBMS_CLOUD` package to **PPTXJSON** user.

    ````sql
    <copy>
    grant execute on DBMS_CLOUD to PPTXJSON;
    </copy>
    ````

    ![Grant DBMS_CLOUD](./images/grant-dbms-cloud.png "")

3. On the cloud console, click on user menu ðŸ‘¤ in the upper-right corner, then click your **oci-username** under Profile.

    ![OCI username](./images/oci-username.png "")

4. Check if you user account is federated.

    ![User information](./images/user-information.png "")

5. In the lower-left Resources menu, click **Auth Tokens**.

    ![Auth Tokens](./images/auth-tokens.png "")

6. Click **Generate Token**.

    - Description: PPTX to JSON

    ![Generate Token](./images/generate-token.png "")

7. Click **Generate Token**. Copy this password for your records. It will not be shown again.

    ![Copy Token](./images/copy-token.png "")

8. Click **Copy** and paste it in your notes. This is your Token value. Now close the dialog.

9. Switch to the browser tab where PPTXJSON user is connected to Database Actions. It should be on the SQL Worksheet.

10. Run the following code to create cloud credentials into your autonomous database using **Run Script** button or F5. Depending on your account, you may need to use `oracleidentitycloudservice/` if it is federated.

    ````sql
    <copy>
    SET DEFINE OFF;
    BEGIN
        DBMS_CLOUD.create_credential(
        credential_name => 'CLOUD_CREDENTIAL',
        username => '[oracleidentitycloudservice/]<oci-username>',
        password => '<token>');
    END;
    /
    </copy>
    ````

    ![Create Credential](./images/create-credential.png "")

11. Test access to your PPTX bucket using the cloud credentials. This query must return the PPTX file you uploaded into LLXXX-PPTX bucket.

    ````sql
    <copy>
    SELECT * FROM table(dbms_cloud.list_objects(
            credential_name => 'CLOUD_CREDENTIAL',
            location_uri => 'https://swiftobjectstorage.<region>.oraclecloud.com/v1/<bucket namespace>/LLXXX-PPTX/'));
    </copy>
    ````


## Task 2: Create processing status table and view

1. Create a new table to store processed presentations.

    ````sql
    <copy>
    create table PPTX_DONE (
      PPTX_ID   NUMBER GENERATED BY DEFAULT ON NULL AS IDENTITY (CACHE 5) primary key,
      PPTX_NAME VARCHAR2(256) not null,
      PROCESSED	DATE
     );
     </copy>
     ````

2. Run the following code to create an external table with all JSON files in the `LLXXX-JSON` bucket that will be written to a `json_files.csv` flat file. Click **Run Script** button or F5.

    ````sql
    <copy>
    declare
     oci_bucket VARCHAR2(128) default 'https://swiftobjectstorage.<region>.oraclecloud.com/v1/<bucket namespace>/LLXXX-JSON/';
    begin
     dbms_cloud.create_external_table(
        table_name =>'JSON_FILES',
        credential_name =>'CLOUD_CREDENTIAL',
        file_uri_list => oci_bucket || 'json_files.csv',
        format => json_object('type' VALUE 'CSV'),
        column_list => 'FILE_NAME  VARCHAR2(256)'
     );
    end;
    /
    </copy>
    ````

3. Create a view to list all PPTX files uploaded into LLXXX-PPTX bucket, and whether or not have been processed.

    ````sql
    <copy>
    create or replace editionable view V_PPTX_DONE as
    SELECT substr(obst.object_name,1,length(obst.object_name)-5) pptx_name,
           obst.object_name,
           obst.bytes/1024/1024 size_mb,
           to_date(substr(obst.last_modified,1,18), 'DD-MON-RR HH24.MI.SS') modified,
           ppd.pptx_name pptx_done,
           ppd.processed,
           jd.json_done
      FROM table(dbms_cloud.list_objects(credential_name => 'CLOUD_CREDENTIAL',
              location_uri => 'https://swiftobjectstorage.<region>.oraclecloud.com/v1/<bucket namespace>/LLXXX-PPTX/')) obst
      left join PPTX_DONE ppd on substr(obst.object_name,1,length(obst.object_name)-5) = ppd.pptx_name
      left join (select unique NVL(SUBSTR(FILE_NAME, 0, INSTR(FILE_NAME, '/')-1), FILE_NAME) as JSON_DONE from JSON_FILES) jd
        on jd.JSON_DONE = substr(obst.object_name,1,length(obst.object_name)-5);
    </copy>
    ````

4. Select all records from `V_PPTX_DONE`, and notice your PPTX file hasn't been processed yet.

    ````sql
    <copy>
    select * from V_PPTX_DONE;
    </copy>
    ````


## Task 3: Create unprocessed presentations procedure

1. Create a procedure to list unprocessed presentations from LLXXX-PPTX bucket and write them in a flat file into LLXXX-JSON bucket, where they will be processed. Use **Run Script** button or F5 to run this code.

    ````sql
    <copy>
    create or replace PROCEDURE TO_PROCESS_CSV AUTHID CURRENT_USER IS
      my_blob_data BLOB;
    BEGIN
    select utl_raw.cast_to_raw (listagg(PPTX_NAME,'
    ')) into my_blob_data from V_PPTX_DONE where PPTX_DONE is NULL;
    DBMS_CLOUD.PUT_OBJECT(
         credential_name => 'CLOUD_CREDENTIAL',
         object_uri => 'https://objectstorage.<region>.oraclecloud.com/n/<bucket namespace>/b/LLXXX-JSON/o/to_process.csv',
         contents => my_blob_data);
    END to_process_csv;
    /
    </copy>
    ````

2. Run the `TO_PROCESS_CSV` procedure.

    ````sql
    <copy>
    exec to_process_csv;
    </copy>
    ````


## Task 4: Write and execute PPTX to JSON conversion script

1. Connect to the LLXXX-VM compute instance using SSH.

2. Go to LLPPTX-JSON folder.

    ````bash
    <copy>
    cd LLPPTX-JSON
    </copy>
    ````

3. Use a text editor on your computer (Notepad) to create a new text file with the following contents.

    ````bash
    <copy>
    #!/bin/bash

    # save current Internal Field Separator (IFS)
    SAVEIFS=IFS
    # set end of line as separator when reading files
    IFS=$(echo -en "\n\b")

    # add end of file to to_process.csv
    echo "" >> to_process.csv

    # read every entry in to_process.csv file
    while read -r p; do
    # display this entry value
      echo ${p}
    # list PPTX file corresponding to this entry
      ls ../LLPPTX-PPTX/${p}*
    # copy new PPTX to processing bucket as ZIP file
      cp ../LLPPTX-PPTX/${p}* ./${p}.zip
    # extract files
      unzip ${p}.zip -d ${p}
    # add this entry's XML file names to CSV file
      find ./${p}/ -iname '*.xml' | sed 's/^.\///g' > new_xml_files.csv
    done <to_process.csv

    # read every XML file in new_xml_files.csv file
    while read p; do
    # check if XML was already converted to JSON
      if [ ! -f ${p::-3}json ]
      then
    # if JSON file doesn't exist
        echo "No JSON file duplicate - OK."
    # display the name of the new JSON file
        echo "Converting ${p::-3}json"
    # add XML file name to CSV for external table
        echo "${p}" >> xml_files.csv
    # perform XML to JSON conversion with XQ
        cat $p | xq . > ${p::-3}json
    # add JSON file name to CSV for external table
        echo "${p::-3}json" >> json_files.csv
      else
    # if JSON file exists, do nothing
        echo "File found ${p::-3}json. Skip."
      fi
    done <new_xml_files.csv

    # revert to original IFS
    IFS=$SAVEIFS
    </copy>
    ````

4. This is the conversion script. Take some time to read the comments in order to understand the process.

5. Save this file as `convert2json.sh` on your computer, and upload it to **LLXXX-JSON** bucket.

6. Use the SSH connection to the LLXXX-VM compute instance to make the conversion script executable.

    ````bash
    <copy>
    chmod u+x convert2json.sh
    </copy>
    ````

7. Convert the conversion script from Windows to Linux text format.

    ````bash
    <copy>
    dos2unix convert2json.sh
    </copy>
    ````

8. Execute the conversion script.

    ````bash
    <copy>
    ./convert2json.sh
    </copy>
    ````

9. The conversion script unpacked the ZIP archive into a folder with the same name as your PPTX presentation. It converted the XML files to JSON. It also wrote all XML files as a list into the `xml_files.csv` flat file, and all JSON files into `json_files.csv` flat file.

    ````bash
    <copy>
    ls
    </copy>
    ````

    You may now **proceed to the next lab**.

## Acknowledgements

- **Author** - Valentin Leonard Tabacaru
- **Last Updated By/Date** - Valentin Leonard Tabacaru, DB Product Management, January 2023
